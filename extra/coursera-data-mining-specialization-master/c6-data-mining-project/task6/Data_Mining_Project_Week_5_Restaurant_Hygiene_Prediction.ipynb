{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Mining_Project_Week_5_Restaurant_Hygiene_Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2CV34UsON7Ic"
      },
      "source": [
        "# Data Mining Project - Week 5 - Restaurant Hygiene Prediction\n",
        "\n",
        "## Data Mining Specialization - Coursera / University of Illinois at Urbana-Champaign\n",
        "\n",
        "* Author: Michael Onishi\n",
        "* Date: November, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ioZUy0CcJxUk"
      },
      "source": [
        "### Description\n",
        "In this task, you are going to predict whether a set of restaurants will pass the public health inspection tests given the corresponding Yelp text reviews along with some additional information such as the locations and cuisines offered in these restaurants.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mSFe8cB1gjNP"
      },
      "source": [
        "### Dataset setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5OEFFBil3T6o",
        "outputId": "a64d0394-e358-4df8-93f1-9eaf78a6e462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "! wget https://d396qusza40orc.cloudfront.net/dataminingcapstone/Task6/Hygiene.tar.gz\n",
        "! tar xzf Hygiene.tar.gz"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-24 20:02:05--  https://d396qusza40orc.cloudfront.net/dataminingcapstone/Task6/Hygiene.tar.gz\n",
            "Resolving d396qusza40orc.cloudfront.net (d396qusza40orc.cloudfront.net)... 13.224.63.146, 13.224.63.17, 13.224.63.183, ...\n",
            "Connecting to d396qusza40orc.cloudfront.net (d396qusza40orc.cloudfront.net)|13.224.63.146|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39134299 (37M) [application/x-gzip]\n",
            "Saving to: ‘Hygiene.tar.gz’\n",
            "\n",
            "Hygiene.tar.gz      100%[===================>]  37.32M  31.6MB/s    in 1.2s    \n",
            "\n",
            "2019-11-24 20:02:07 (31.6 MB/s) - ‘Hygiene.tar.gz’ saved [39134299/39134299]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X5FO7T0loooH",
        "outputId": "b7f29c52-43b3-4d2d-b36c-b88f3d7a1ed6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "! pip install unidecode"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 5.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 71kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 102kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 112kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 122kB 8.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 133kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 143kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 153kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 163kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 174kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 184kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 194kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 204kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 215kB 8.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 225kB 8.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 235kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 8.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ef4yMrGWnxa-",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unidecode import unidecode\n",
        "import re\n",
        "import math\n",
        "import html\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "\n",
        "\n",
        "# Plotting tools\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "\n",
        "# Seaborn for plotting and styling\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgoP0ct24YcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('Hygiene/hygiene.dat', header=None, delimiter='\\n', names=['reviews'])\n",
        "\n",
        "# some reviews have html entities like &#160;. convert them to clean text.\n",
        "df.reviews = df.reviews.apply(lambda x : html.unescape(x))\n",
        "df['label'] = np.loadtxt('Hygiene/hygiene.dat.labels', dtype = str, delimiter='\\n')\n",
        "df2 = pd.read_csv('Hygiene/hygiene.dat.additional', header=None, names=['categories', 'zip', 'review_count', 'average_rating'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90S4o4HtqW6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([df2, df], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI-5vDJsoQ_r",
        "colab_type": "code",
        "outputId": "61b0c0c2-e97e-4aa2-be33-3d0ef96609bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>zip</th>\n",
              "      <th>review_count</th>\n",
              "      <th>average_rating</th>\n",
              "      <th>reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Vietnamese', 'Sandwiches', 'Restaurants']</td>\n",
              "      <td>98118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>The baguettes and rolls are excellent, and alt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['American (New)', 'Restaurants']</td>\n",
              "      <td>98109</td>\n",
              "      <td>21</td>\n",
              "      <td>4.047619</td>\n",
              "      <td>I live up the street from Betty.  When my sist...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['Mexican', 'Restaurants']</td>\n",
              "      <td>98103</td>\n",
              "      <td>14</td>\n",
              "      <td>3.111111</td>\n",
              "      <td>I'm worried about how I will review this place...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Mexican', 'Tex-Mex', 'Restaurants']</td>\n",
              "      <td>98112</td>\n",
              "      <td>42</td>\n",
              "      <td>4.088889</td>\n",
              "      <td>Why can't you access them on Google street vie...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Mexican', 'Restaurants']</td>\n",
              "      <td>98102</td>\n",
              "      <td>12</td>\n",
              "      <td>3.071429</td>\n",
              "      <td>Things to like about this place: homemade guac...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13294</th>\n",
              "      <td>['Dim Sum', 'Cantonese', 'Chinese', 'Restauran...</td>\n",
              "      <td>98104</td>\n",
              "      <td>1</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>I keep my Dim Sum dining expectations very low...</td>\n",
              "      <td>[None]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13295</th>\n",
              "      <td>['Breakfast &amp; Brunch', 'Restaurants']</td>\n",
              "      <td>98116</td>\n",
              "      <td>29</td>\n",
              "      <td>4.258065</td>\n",
              "      <td>Cheap eats and veggie alterna-meats... Perfect...</td>\n",
              "      <td>[None]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13296</th>\n",
              "      <td>['Vietnamese', 'Restaurants']</td>\n",
              "      <td>98104</td>\n",
              "      <td>1</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>Everything here is awesome except for the wait...</td>\n",
              "      <td>[None]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13297</th>\n",
              "      <td>['Italian', 'Pizza', 'Restaurants']</td>\n",
              "      <td>98109</td>\n",
              "      <td>2</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>A great place to go on Queen Anne when everywh...</td>\n",
              "      <td>[None]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13298</th>\n",
              "      <td>['Sandwiches', 'Restaurants']</td>\n",
              "      <td>98108</td>\n",
              "      <td>2</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>My union has ordered us lunchboxes from Ingall...</td>\n",
              "      <td>[None]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13299 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              categories  ...   label\n",
              "0            ['Vietnamese', 'Sandwiches', 'Restaurants']  ...       1\n",
              "1                      ['American (New)', 'Restaurants']  ...       1\n",
              "2                             ['Mexican', 'Restaurants']  ...       1\n",
              "3                  ['Mexican', 'Tex-Mex', 'Restaurants']  ...       0\n",
              "4                             ['Mexican', 'Restaurants']  ...       0\n",
              "...                                                  ...  ...     ...\n",
              "13294  ['Dim Sum', 'Cantonese', 'Chinese', 'Restauran...  ...  [None]\n",
              "13295              ['Breakfast & Brunch', 'Restaurants']  ...  [None]\n",
              "13296                      ['Vietnamese', 'Restaurants']  ...  [None]\n",
              "13297                ['Italian', 'Pizza', 'Restaurants']  ...  [None]\n",
              "13298                      ['Sandwiches', 'Restaurants']  ...  [None]\n",
              "\n",
              "[13299 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZfZJsyPn2-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df[df.label != '[None]'].copy()\n",
        "df_test = df[df.label == '[None]'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLXXVSmcrEcP",
        "colab_type": "text"
      },
      "source": [
        "### Text only classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-piG7nRcC8up",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    # Remove accents\n",
        "    text = unidecode(text)\n",
        "    # Remove line breaks and tab\n",
        "    text = re.sub(r'[\\t\\n\\r]', ' ', text)\n",
        "    # Remove http links\n",
        "    text = re.sub(r'http\\S+', ' ', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower().strip()    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "92QahoR4nYIl",
        "colab": {}
      },
      "source": [
        "df_train.reviews = df_train.reviews.apply(lambda x : preprocess(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkcDkdohHbXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize(text_list, max_features=20000, ngram_range=(1,1)):\n",
        "    print(f\"Vectorizing {len(text_list)} documents using {max_features} max_features\")\n",
        "    vectorizer = TfidfVectorizer(max_df=0.8, max_features=max_features,\n",
        "                             min_df=2, stop_words='english',\n",
        "                             use_idf=False,\n",
        "                             ngram_range=ngram_range,\n",
        "                             token_pattern='[a-zA-Z0-9]{3,}')\n",
        "    \n",
        "    return vectorizer, vectorizer.fit_transform(text_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RMnYoA_Hpe3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "148faa8e-5b9a-4a47-f46c-42aa92ae1c58"
      },
      "source": [
        "%%time\n",
        "vectorizer_unigram, matrix_unigram = vectorize(df_train.reviews, max_features = 100000, ngram_range=(1,1))\n",
        "vectorizer_bigram, matrix_bigram = vectorize(df_train.reviews, max_features = 100000, ngram_range=(1,2))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vectorizing 546 documents using 100000 max_features\n",
            "Vectorizing 546 documents using 100000 max_features\n",
            "CPU times: user 2.06 s, sys: 53.1 ms, total: 2.11 s\n",
            "Wall time: 2.11 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "8b99b5c7-e306-4746-fe02-7727df5e71a6",
        "id": "RsArJ3jNH7Am",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(matrix_unigram.shape, matrix_bigram.shape)"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(546, 10740) (546, 46729)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDN1KZQSJawr",
        "colab_type": "text"
      },
      "source": [
        "**Since we do not have access to any label in the test set, I will select 10% of the original training set to be my test set to be able to calculate the f1-score properly.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppv6NXQfosoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_unigram, X_test_unigram, y_train, y_test = train_test_split(matrix_unigram, df_train.label, test_size=0.1, random_state=42)\n",
        "X_train_bigram, X_test_bigram, y_train, y_test = train_test_split(matrix_bigram, df_train.label, test_size=0.1, random_state=42)\n",
        "target_names = ['passed test', 'failed test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAwTnqcZhplq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_predict(X_train, X_test, y_train, y_test):\n",
        "  clf_multinomialNB = MultinomialNB().fit(X_train, y_train)\n",
        "  y_pred_multinomialNB = clf_multinomialNB.predict(X_test)\n",
        "  print('Multinomial Naive Bayes')\n",
        "  print(classification_report(y_test, y_pred_multinomialNB, target_names=target_names))\n",
        "\n",
        "  clf_sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, \n",
        "                      random_state=42, max_iter=10, tol=None).fit(X_train, y_train)\n",
        "  y_pred_sgd = clf_sgd.predict(X_test)\n",
        "  print('\\nSGD')\n",
        "  print(classification_report(y_test, y_pred_sgd, target_names=target_names))\n",
        "\n",
        "  clf_rf = RandomForestClassifier(n_estimators=200, random_state=42).fit(X_train, y_train)\n",
        "  y_pred_rf = clf_rf.predict(X_test)\n",
        "  print('\\nRandom Forest')\n",
        "  print(classification_report(y_test, y_pred_rf, target_names=target_names))\n",
        "\n",
        "  clf_voting = VotingClassifier([('Multinomial Naive Bayes', clf_multinomialNB), ('SGD', clf_sgd), ('Random Forest', clf_rf)]).fit(X_train, y_train)\n",
        "  y_pred_voting = clf_voting.predict(X_test)\n",
        "  print('\\nVoting')\n",
        "  print(classification_report(y_test, y_pred_voting, target_names=target_names))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IZOPlguJFGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "876be64e-95e7-4bda-b302-15bf18e5b629"
      },
      "source": [
        "train_predict(X_train_unigram, X_test_unigram, y_train, y_test)"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.72      0.78      0.75        23\n",
            " failed test       0.83      0.78      0.81        32\n",
            "\n",
            "    accuracy                           0.78        55\n",
            "   macro avg       0.78      0.78      0.78        55\n",
            "weighted avg       0.79      0.78      0.78        55\n",
            "\n",
            "\n",
            "SGD\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.53      0.87      0.66        23\n",
            " failed test       0.82      0.44      0.57        32\n",
            "\n",
            "    accuracy                           0.62        55\n",
            "   macro avg       0.67      0.65      0.61        55\n",
            "weighted avg       0.70      0.62      0.61        55\n",
            "\n",
            "\n",
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.57      0.91      0.70        23\n",
            " failed test       0.89      0.50      0.64        32\n",
            "\n",
            "    accuracy                           0.67        55\n",
            "   macro avg       0.73      0.71      0.67        55\n",
            "weighted avg       0.75      0.67      0.67        55\n",
            "\n",
            "\n",
            "Voting\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.58      0.91      0.71        23\n",
            " failed test       0.89      0.53      0.67        32\n",
            "\n",
            "    accuracy                           0.69        55\n",
            "   macro avg       0.74      0.72      0.69        55\n",
            "weighted avg       0.76      0.69      0.69        55\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fof8LKsDfJme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "e5ce1e1b-5772-4c3f-fcfd-3649a773225c"
      },
      "source": [
        "train_predict(X_train_bigram, X_test_bigram, y_train, y_test)"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.68      0.65      0.67        23\n",
            " failed test       0.76      0.78      0.77        32\n",
            "\n",
            "    accuracy                           0.73        55\n",
            "   macro avg       0.72      0.72      0.72        55\n",
            "weighted avg       0.73      0.73      0.73        55\n",
            "\n",
            "\n",
            "SGD\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.51      0.91      0.66        23\n",
            " failed test       0.86      0.38      0.52        32\n",
            "\n",
            "    accuracy                           0.60        55\n",
            "   macro avg       0.68      0.64      0.59        55\n",
            "weighted avg       0.71      0.60      0.58        55\n",
            "\n",
            "\n",
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.56      1.00      0.72        23\n",
            " failed test       1.00      0.44      0.61        32\n",
            "\n",
            "    accuracy                           0.67        55\n",
            "   macro avg       0.78      0.72      0.66        55\n",
            "weighted avg       0.82      0.67      0.65        55\n",
            "\n",
            "\n",
            "Voting\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.57      0.91      0.70        23\n",
            " failed test       0.89      0.50      0.64        32\n",
            "\n",
            "    accuracy                           0.67        55\n",
            "   macro avg       0.73      0.71      0.67        55\n",
            "weighted avg       0.75      0.67      0.67        55\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf1UR6dkcQrt",
        "colab_type": "text"
      },
      "source": [
        "### Metadata only classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtAfXty6rlUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['average_rating_scaled'] = preprocessing.minmax_scale(df_train.average_rating)\n",
        "df_train['review_count_scaled'] = preprocessing.minmax_scale(df_train.review_count)\n",
        "df_train.zip = df_train.zip.apply(str)\n",
        "df_train['cat_list'] = df_train.categories.apply(lambda x : x[2:-2].split(\"', '\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6oNcgmCuI15",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f21e25c4-aa5b-445b-fc05-a0cb6a3f199c"
      },
      "source": [
        "df_train[['average_rating_scaled', 'review_count_scaled', 'cat_list']]"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_rating_scaled</th>\n",
              "      <th>review_count_scaled</th>\n",
              "      <th>cat_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>[Vietnamese, Sandwiches, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.144928</td>\n",
              "      <td>[American (New), Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.094203</td>\n",
              "      <td>[Mexican, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.772222</td>\n",
              "      <td>0.297101</td>\n",
              "      <td>[Mexican, Tex-Mex, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.517857</td>\n",
              "      <td>0.079710</td>\n",
              "      <td>[Mexican, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.014493</td>\n",
              "      <td>[Mexican, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>0.527778</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>[Chinese, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>0.612500</td>\n",
              "      <td>0.123188</td>\n",
              "      <td>[Pizza, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.065217</td>\n",
              "      <td>[Vietnamese, Sandwiches, Restaurants]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>0.682432</td>\n",
              "      <td>0.239130</td>\n",
              "      <td>[Vegetarian, Vegan, Restaurants]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>546 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     average_rating_scaled  ...                               cat_list\n",
              "0                 0.750000  ...  [Vietnamese, Sandwiches, Restaurants]\n",
              "1                 0.761905  ...          [American (New), Restaurants]\n",
              "2                 0.527778  ...                 [Mexican, Restaurants]\n",
              "3                 0.772222  ...        [Mexican, Tex-Mex, Restaurants]\n",
              "4                 0.517857  ...                 [Mexican, Restaurants]\n",
              "..                     ...  ...                                    ...\n",
              "541               0.916667  ...                 [Mexican, Restaurants]\n",
              "542               0.527778  ...                 [Chinese, Restaurants]\n",
              "543               0.612500  ...                   [Pizza, Restaurants]\n",
              "544               0.825000  ...  [Vietnamese, Sandwiches, Restaurants]\n",
              "545               0.682432  ...       [Vegetarian, Vegan, Restaurants]\n",
              "\n",
              "[546 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyJ_E28CTI6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_metadata, X_test_metadata, y_train, y_test = train_test_split(\n",
        "    pd.concat([df_train[['average_rating_scaled', 'review_count_scaled', 'zip']], \n",
        "               pd.DataFrame(preprocessing.MultiLabelBinarizer().fit_transform(df_train.cat_list))],\n",
        "              axis = 1)\n",
        "    , df_train.label, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7qVlh7Fwph4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "067e2507-6aa2-49c9-dd98-8b99c76da641"
      },
      "source": [
        "train_predict(X_train_metadata, X_test_metadata, y_train, y_test)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.62      0.91      0.74        23\n",
            " failed test       0.90      0.59      0.72        32\n",
            "\n",
            "    accuracy                           0.73        55\n",
            "   macro avg       0.76      0.75      0.73        55\n",
            "weighted avg       0.78      0.73      0.73        55\n",
            "\n",
            "\n",
            "SGD\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.42      1.00      0.59        23\n",
            " failed test       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.42        55\n",
            "   macro avg       0.21      0.50      0.29        55\n",
            "weighted avg       0.17      0.42      0.25        55\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.50      0.78      0.61        23\n",
            " failed test       0.74      0.44      0.55        32\n",
            "\n",
            "    accuracy                           0.58        55\n",
            "   macro avg       0.62      0.61      0.58        55\n",
            "weighted avg       0.64      0.58      0.57        55\n",
            "\n",
            "\n",
            "Voting\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.51      0.96      0.67        23\n",
            " failed test       0.92      0.34      0.50        32\n",
            "\n",
            "    accuracy                           0.60        55\n",
            "   macro avg       0.71      0.65      0.58        55\n",
            "weighted avg       0.75      0.60      0.57        55\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_ZH4eDgGiYx",
        "colab_type": "text"
      },
      "source": [
        "### Combined classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HoM17PYD_uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf_multinomialNB = MultinomialNB().fit(X_train_unigram, y_train)\n",
        "df_train['text_prediction'] = clf_multinomialNB.predict(matrix_unigram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DTvjiIiwsOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_all, X_test_all, y_train, y_test = train_test_split(\n",
        "    pd.concat([df_train[['average_rating_scaled', 'review_count_scaled', 'zip', 'text_prediction']], \n",
        "               pd.DataFrame(preprocessing.MultiLabelBinarizer().fit_transform(df_train.cat_list))],\n",
        "              axis = 1)\n",
        "    , df_train.label, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hak3fnw8IMJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "6f8b1301-9d0f-418c-ba2a-cc58e7b2a706"
      },
      "source": [
        "train_predict(X_train_all, X_test_all, y_train, y_test)"
      ],
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Multinomial Naive Bayes\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.70      0.91      0.79        23\n",
            " failed test       0.92      0.72      0.81        32\n",
            "\n",
            "    accuracy                           0.80        55\n",
            "   macro avg       0.81      0.82      0.80        55\n",
            "weighted avg       0.83      0.80      0.80        55\n",
            "\n",
            "\n",
            "SGD\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.42      1.00      0.59        23\n",
            " failed test       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.42        55\n",
            "   macro avg       0.21      0.50      0.29        55\n",
            "weighted avg       0.17      0.42      0.25        55\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Random Forest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.67      0.78      0.72        23\n",
            " failed test       0.82      0.72      0.77        32\n",
            "\n",
            "    accuracy                           0.75        55\n",
            "   macro avg       0.74      0.75      0.74        55\n",
            "weighted avg       0.76      0.75      0.75        55\n",
            "\n",
            "\n",
            "Voting\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " passed test       0.63      0.96      0.76        23\n",
            " failed test       0.95      0.59      0.73        32\n",
            "\n",
            "    accuracy                           0.75        55\n",
            "   macro avg       0.79      0.78      0.74        55\n",
            "weighted avg       0.82      0.75      0.74        55\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eODeMI8d_4Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}